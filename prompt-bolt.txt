make a slick user interface with light/dark mode using a modern JS framework. The app "Openrouter Model Browser" lists all LLMs from this API: https://openrouter.ai/api/v1/models

we want
o) model name (sorted by everything after the /)
o) release date (Day + Name of Month + Year) - based on utime created
o) context length
o) description

default list sorted by: latest model first.
user can sort asc/desc by date and context window
data looks like this

"data": [
{
"id": "raifle/sorcererlm-8x22b",
"name": "Sorcererlm 8x22b",
"created": 1731105083,
"description": "SorcererLM is an advanced RP and storytelling model, built as a Low-rank 16-bit LoRA fine-tuned on WizardLM-2-8x22B.\n\n- Advanced reasoning and emotional intelligence for engaging and immersive interactions\n- Vivid writing capabilities enriched with spatial and contextual awareness\n- Enhanced narrative depth, promoting creative and dynamic storytelling",
"context_length": 16000,
"architecture": {
"modality": "text->text",
"tokenizer": "Mistral",
"instruct_type": "vicuna"
},
"pricing": {
"prompt": "0.0000045",
"completion": "0.0000045",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 16000,
"max_completion_tokens": null,
"is_moderated": false
},
"per_request_limits": null
},
{
"id": "eva-unit-01/eva-qwen-2.5-32b",
"name": "Eva Qwen2.5 32B",
"created": 1731104847,
"description": "A roleplaying/storywriting specialist model, full-parameter finetune of Qwen2.5-32B on mixture of synthetic and natural data.\n\nIt uses Celeste 70B 0.1 data mixture, greatly expanding it to improve versatility, creativity and "flavor" of the resulting model.",
"context_length": 32000,
"architecture": {
"modality": "text->text",
"tokenizer": "Qwen",
"instruct_type": "chatml"
},
"pricing": {
"prompt": "0.0000005",
"completion": "0.0000005",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 32000,
"max_completion_tokens": null,
"is_moderated": false
},
"per_request_limits": null
},
{
"id": "anthropic/claude-3-5-haiku-20241022:beta",
"name": "Anthropic: Claude 3.5 Haiku (2024-10-22) (self-moderated)",
"created": 1730678400,
"description": "Claude 3.5 Haiku features enhancements across all skill sets including coding, tool use, and reasoning. As the fastest model in the Anthropic lineup, it offers rapid response times suitable for applications that require high interactivity and low latency, such as user-facing chatbots and on-the-fly code completions. It also excels in specialized tasks like data extraction and real-time content moderation, making it a versatile tool for a broad range of industries.\n\nIt does not support image inputs.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)",
"context_length": 200000,
"architecture": {
"modality": "text->text",
"tokenizer": "Claude",
"instruct_type": null
},
"pricing": {
"prompt": "0.000001",
"completion": "0.000005",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 200000,
"max_completion_tokens": 8192,
"is_moderated": false
},
"per_request_limits": null
},
{
"id": "anthropic/claude-3-5-haiku-20241022",
"name": "Anthropic: Claude 3.5 Haiku (2024-10-22)",
"created": 1730678400,
"description": "Claude 3.5 Haiku features enhancements across all skill sets including coding, tool use, and reasoning. As the fastest model in the Anthropic lineup, it offers rapid response times suitable for applications that require high interactivity and low latency, such as user-facing chatbots and on-the-fly code completions. It also excels in specialized tasks like data extraction and real-time content moderation, making it a versatile tool for a broad range of industries.\n\nIt does not support image inputs.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/3-5-models-and-computer-use)",
"context_length": 200000,
"architecture": {
"modality": "text->text",
"tokenizer": "Claude",
"instruct_type": null
},
"pricing": {
"prompt": "0.000001",
"completion": "0.000005",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 200000,
"max_completion_tokens": 8192,
"is_moderated": true
},
"per_request_limits": null
},
{
"id": "anthropic/claude-3-5-haiku:beta",
"name": "Anthropic: Claude 3.5 Haiku (self-moderated)",
"created": 1730678400,
"description": "Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).",
"context_length": 200000,
"architecture": {
"modality": "text->text",
"tokenizer": "Claude",
"instruct_type": null
},
"pricing": {
"prompt": "0.000001",
"completion": "0.000005",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 200000,
"max_completion_tokens": 8192,
"is_moderated": false
},
"per_request_limits": null
},
{
"id": "anthropic/claude-3-5-haiku",
"name": "Anthropic: Claude 3.5 Haiku",
"created": 1730678400,
"description": "Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use. Engineered to excel in real-time applications, it delivers quick response times that are essential for dynamic tasks such as chat interactions and immediate coding suggestions.\n\nThis makes it highly suitable for environments that demand both speed and precision, such as software development, customer service bots, and data management systems.\n\nThis model is currently pointing to [Claude 3.5 Haiku (2024-10-22)](/anthropic/claude-3-5-haiku-20241022).",
"context_length": 200000,
"architecture": {
"modality": "text->text",
"tokenizer": "Claude",
"instruct_type": null
},
"pricing": {
"prompt": "0.000001",
"completion": "0.000005",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 200000,
"max_completion_tokens": 8192,
"is_moderated": true
},
"per_request_limits": null
},
{
"id": "neversleep/llama-3.1-lumimaid-70b",
"name": "Lumimaid v0.2 70B",
"created": 1729555200,
"description": "Lumimaid v0.2 70B is a finetune of [Llama 3.1 70B](/meta-llama/llama-3.1-70b-instruct) with a "HUGE step up dataset wise" compared to Lumimaid v0.1. Sloppy chats output were purged.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
"context_length": 16384,
"architecture": {
"modality": "text->text",
"tokenizer": "Llama3",
"instruct_type": "llama3"
},
"pricing": {
"prompt": "0.000003375",
"completion": "0.0000045",
"image": "0",
"request": "0"
},
"top_provider": {
"context_length": 16384,
"max_completion_tokens": 2048,
"is_moderated": false
},
"per_request_limits": null
},
{
"id": "anthracite-org/magnum-v4-72b",
"name": "Magnum v4 72B",
